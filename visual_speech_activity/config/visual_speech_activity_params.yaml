# ROS2 Parameters for Visual Speech Activity Detection Node
# This file contains all configurable parameters for the VisualSpeechActivityNode

visual_speech_activity_node:
  ros__parameters:
    # Topic Configuration
    recognition_input_topic: "/humans/faces/recognized"
    landmarks_input_topic: "/humans/faces/detected"
    output_topic: "/humans/faces/speaking"
    
    # ROS4HRI Configuration
    # Set to true for per-ID topics (/humans/faces/<id>/speaking)
    # Set to false for array mode (/humans/faces/speaking with FacialRecognitionArray)
    ros4hri_with_id: true
    
    # Lip Movement Detection Parameters
    
    # Number of frames to analyze in temporal buffer
    # Higher values = more stable but slower response
    # Recommended: 15-30 frames
    window_size: 10
    
    # Minimum mouth aspect ratio variation to detect movement
    # Lower values = more sensitive
    # Recommended: 0.01-0.05
    movement_threshold: 0.01
    
    # Confidence threshold for speaking classification
    # Higher values = fewer false positives but may miss speaking
    # Recommended: 0.4-0.6
    speaking_threshold: 0.90
    
    # Enable temporal smoothing to reduce jitter
    # Applies voting over last 5 frames
    temporal_smoothing: true
    
    # Minimum frames required before starting detection
    # Prevents unreliable detection from insufficient data
    # Recommended: 3-10 frames
    min_frames_for_detection: 5
    
    # Enhanced Detection Parameters
    
    # Use full 68-point dlib landmarks when available (recommended)
    # Falls back to 5-point landmarks automatically if not available
    use_full_landmarks: true
    
    # Enable RNN-based temporal classification (recommended for accuracy)
    # Falls back to simple threshold-based detection if disabled
    # Note: RNN requires training data - use simple mode for better results with untrained weights
    rnn_enabled: false
    
    # Face Recognition Integration
    # Set to true to use face recognition for robust identity tracking (recommended)
    # Set to false to work with face_id only (fallback when face recognition unavailable)
    use_face_recognition: false
    
    # Debug Configuration
    enable_debug_output: true
